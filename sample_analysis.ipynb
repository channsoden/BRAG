{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BRAG Demo\n",
    "\n",
    "This notebook will re-create all figures and statistical analyses presented in Hann-Soden et al (2018)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "step = 4000\n",
    "window_size = 20000\n",
    "\n",
    "genome_file = 'genomes/Neurospora-crassa_OR74A_v12_fixed.fasta'\n",
    "annotation_file = 'genomes/annotations/Neurospora_crassa_OR74A_v12_fixed.gtf'\n",
    "centromere_file = 'Neurospora-crassa_v12_fixed_centromeres.txt'\n",
    "segment_files = 'alignments/Neurospora.*.os.txt'\n",
    "seqs_files = 'alignments/Neurospora.*.seqs'\n",
    "tree_file = 'Neurospora.nwk'\n",
    "reference_name = 'Nc'\n",
    "outgroup_name = 'Sm'\n",
    "output_prefix = 'Ncrassa'\n",
    "core_gene_file = 'takao_core_genes.tsv'\n",
    "core_gene_key = 'takao_core_genes_key.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the environment\n",
    "import sys, os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from scipy import stats\n",
    "import statsmodels.stats.multitest as smm\n",
    "\n",
    "from BRAG_parsers import scaffold_table\n",
    "from fasta_tools import fasta_to_dict\n",
    "from gff_tools import gff_table\n",
    "from plots import regression_plot, pretty_bar\n",
    "from plotting_tools import direct_labels\n",
    "\n",
    "BRAGdir = os.getcwd()\n",
    "\n",
    "sys.path.append(BRAGdir)\n",
    "sys.path.append(BRAGdir+'/hannsoden-bioinformatics')\n",
    "\n",
    "os.chdir('sample_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the genomes used in the study\n",
    "import urllib.request, tarfile\n",
    "\n",
    "genome_source = 'https://osf.io/vmkc8/?action=download'\n",
    "genome_target = 'genomes.tar.gz'\n",
    "response = urllib.request.urlretrieve(genome_source, genome_target)\n",
    "\n",
    "tar = tarfile.open(genome_target, 'r:gz')\n",
    "tar.extractall()\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the extra tracks used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fasta_tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-271df57acd67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mBRAG_parsers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscaffold_table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfasta_tools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfasta_to_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgff_tools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgff_table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/BRAG/BRAG_parsers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# My modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfasta_tools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_absolute_positions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msakakibara_tools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_sakakibara\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fasta_tools'"
     ]
    }
   ],
   "source": [
    "def windowize(genome, step=4000, window_size=20000):\n",
    "    # Produce start and end coordinates of sliding windows\n",
    "    start = 0\n",
    "    end = start + window_size\n",
    "    genlen = len(genome)\n",
    "    while end < genlen:\n",
    "        yield (start, end)\n",
    "        start += step\n",
    "        end += step\n",
    "\n",
    "def flatten(df):\n",
    "    # Merge overlapping regions into a single presence/absence layer.\n",
    "    # Assumes df is sorted.\n",
    "    regions = {'start':[], 'end':[]}\n",
    "    region_start = 0\n",
    "    region_end = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if row.abs_start > region_end:\n",
    "            regions['start'].append(region_start)\n",
    "            regions['end'].append(region_end)\n",
    "            region_start = row.abs_start\n",
    "        region_end = row.abs_end\n",
    "    regions['start'] = regions['start'][1:]\n",
    "    regions['end'] = regions['end'][1:]\n",
    "    return pd.DataFrame(regions)\n",
    "\n",
    "def GC(seq):\n",
    "    gc = seq.count('G') + seq.count('C')\n",
    "    gc = float(gc) / len(seq)\n",
    "    return gc\n",
    "\n",
    "def CRI(seq):\n",
    "    # composite rip index = (TA/AT)- (CA+TG)/(AC+GT)\n",
    "    TA = float(seq.count('TA'))+1\n",
    "    AT = float(seq.count('AT'))+1\n",
    "    CA = float(seq.count('CA'))+1\n",
    "    TG = float(seq.count('TG'))+1\n",
    "    AC = float(seq.count('AC'))+1\n",
    "    GT = float(seq.count('GT'))+1\n",
    "    return (TA/AT) - (CA+TG)/(AC+GT)\n",
    "\n",
    "def gene_density(annotation, window):\n",
    "    start, end = window\n",
    "    window_size = float(end - start)\n",
    "    overlapping = annotation.loc[(annotation.start < end) & (annotation.end > start)]\n",
    "    start = np.full( len(overlapping), start, dtype=int)\n",
    "    starts = np.maximum(start, overlapping.start)\n",
    "    end = np.full( len(overlapping), end, dtype=int)\n",
    "    ends = np.minimum(end, overlapping.end)\n",
    "    overlap = np.sum(ends - starts)\n",
    "    return overlap / window_size\n",
    "\n",
    "# Read in the reference genome and concatenate it into a single string.\n",
    "fasta = open(genome_file, 'r').read()\n",
    "scaffolds = fasta[1:].split('>')\n",
    "scaffolds = [s.split('\\n', 1) for s in scaffolds]\n",
    "scaffolds = [s[1].replace('\\n', '') for s in scaffolds]\n",
    "genome = ''.join(scaffolds)\n",
    "\n",
    "# Read in the annotation and calculate coordinates for features based on\n",
    "# the concatenated genome sequence, rather than for each scaffold.\n",
    "annotation = gff_table(annotation_file)\n",
    "scaffolds = scaffold_table(genome_file)\n",
    "abs_positions = {row['name']: row.abs_pos for i, row in scaffolds.iterrows()}\n",
    "scaf_adjustment = annotation.seqname.replace(abs_positions)\n",
    "annotation['abs_start'] = annotation.start + scaf_adjustment\n",
    "annotation['abs_end'] = annotation.end + scaf_adjustment\n",
    "annotation.sort_values('abs_start', inplace=True)\n",
    "\n",
    "# Find protein coding and expressed regions of the genome.\n",
    "# Flattening avoids double counting regions that are in multiple transcripts.\n",
    "protein_coding = annotation.loc[annotation.feature == 'CDS']\n",
    "protein_coding = flatten(protein_coding)\n",
    "expressed = annotation.loc[annotation.feature == 'exon']\n",
    "expressed = flatten(expressed)\n",
    "\n",
    "# Calculate different statistics for each window, put into dataframe.\n",
    "columns = ['start', 'end', 'GC', 'CRI', 'cds_density', 'exon_density']\n",
    "tracks = {column:[] for column in columns}\n",
    "for window in windowize(genome, window_size=window_size, step=step):\n",
    "    seg = genome[slice(*window)]\n",
    "    seg = seg.upper()\n",
    "    tracks['start'].append( window[0] )\n",
    "    tracks['end'].append( window[1] )\n",
    "    tracks['GC'].append( GC(seg) )\n",
    "    tracks['CRI'].append( CRI(seg) )\n",
    "    tracks['cds_density'].append( gene_density(protein_coding, window) )\n",
    "    tracks['exon_density'].append( gene_density(expressed, window) )\n",
    "\n",
    "tracks = pd.DataFrame(tracks)\n",
    "print(tracks)\n",
    "tracks.to_csv('extra_tracks.tsv', sep='\\t', columns = columns, index=False)\n",
    "\n",
    "# CRI and GC are colinear, basically the same thing, so both shouldn't be used for\n",
    "# break rate regression. Exon density and CDS density are also highly related.\n",
    "# Exon density is also heavily affected by RIP, so I want to include exon density\n",
    "# only at un-ripped sites.\n",
    "# Positive scores for CRI indicate RIP.\n",
    "tracks['unripped_exon_density'] = tracks.exon_density\n",
    "tracks.loc[tracks.CRI > 0, 'unripped_exon_density'] = np.NaN\n",
    "\n",
    "# Write dataframe to file.\n",
    "tracks.to_csv('extra_tracks_unique.tsv', sep='\\t',\n",
    "              columns = ['start', 'end', 'CRI', 'unripped_exon_density'],\n",
    "              index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run BRAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/christopher/BRAG/BRAG -t Neurospora.nwk -r Nc -x Sm -o Ncrassa -g alignments/Neurospora.*.os.txt -q alignments/Neurospora.*.seqs -C Neurospora-crassa_v12_fixed_centromeres.txt -T extra_tracks.tsv  -W 20000 -S 4000\n"
     ]
    }
   ],
   "source": [
    "# This would be the command used to run BRAG\n",
    "command = (BRAGdir+'/BRAG -t '+tree_file+' -r '+reference_name+\n",
    "           ' -x '+outgroup_name+' -o '+output_prefix+\n",
    "           ' -g '+segment_files+' -q '+seqs_files+\n",
    "           ' -C '+centromere_file+' -T extra_tracks.tsv '+\n",
    "           ' -W '+str(window_size)+' -S '+str(step))\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run BRAG from Python\n",
    "from BRAG_main import main as BRAG\n",
    "\n",
    "seqs = glob.glob(seqs_files)\n",
    "segs = glob.glob(segment_files)\n",
    "\n",
    "BRAG(tree_file, reference_name, outgroup_name, output_prefix,\n",
    "     segs, seqs, step=step, window_size=window_size,\n",
    "     centromeres=centromere_file, tracks='extra_tracks.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run again with unique tracks\n",
    "BRAG(tree_file, reference_name, outgroup_name, output_prefix+'_unique',\n",
    "     segs, seqs, step=step, window_size=window_size,\n",
    "     centromeres=centromere_file, tracks='extra_tracks_unique.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze results & make figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def telomere_correlations(dataset, chromosomes, datalabel):\n",
    "    dataset['midpoint'] = (dataset.start + dataset.end) / 2.\n",
    "    tests = []\n",
    "    for chr_num, coordinates in enumerate(chromosomes):\n",
    "        label = 'Chr_{}_'.format(chr_num+1)\n",
    "        lstart, lend, rstart, rend = coordinates # coordinates of left and right arms of the chromosomes\n",
    "\n",
    "        larm = dataset.loc[(dataset.start >= lstart) & (dataset.end <= lend)]\n",
    "        rarm = dataset.loc[(dataset.start >= rstart) & (dataset.end <= rend)]\n",
    "\n",
    "        # left arm works from left to right\n",
    "        ltest = regression_plot(larm.midpoint - lstart, larm[datalabel], label=label+'left')\n",
    "        ltest.regress(slope = 'negative')\n",
    "        tests.append(ltest)\n",
    "        # right arm works from right to left\n",
    "        rtest = regression_plot(rend - rarm.midpoint, rarm[datalabel], label=label+'right')\n",
    "        rtest.regress(slope = 'negative')\n",
    "        tests.append(rtest)\n",
    "    return tests\n",
    "\n",
    "def read_centromeres(cen_file, chromosomes):\n",
    "    fh = open(cen_file, 'r')\n",
    "    header = fh.readline()\n",
    "    idxs, starts, stops = list(zip(*[list(map(int, line.split('#')[0].strip().split())) for line in fh]))\n",
    "    centromeres = [[0, max(stops), 0, 0] for x in range(max(idxs)+1)]\n",
    "    for idx, start, stop in zip(idxs, starts, stops):\n",
    "        centromeres[idx][0] = chromosomes.iloc[idx].abs_pos\n",
    "        centromeres[idx][1] = chromosomes.iloc[idx].abs_pos + min(start, centromeres[idx][1])\n",
    "        centromeres[idx][2] = chromosomes.iloc[idx].abs_pos + max(stop, centromeres[idx][2])\n",
    "        centromeres[idx][3] = chromosomes.iloc[idx+1].abs_pos -1\n",
    "    return centromeres\n",
    "\n",
    "certain = pd.read_csv(output_prefix+'_certain_rate_windows.txt', sep='\\t', header=0)\n",
    "uncertain = pd.read_csv(output_prefix+'_uncertain_rate_windows.txt', sep='\\t', header=0)\n",
    "# get the scaffold lengths\n",
    "scaffolds = scaffold_table(genome_file)\n",
    "# calculate the coordinates of left and right arms of the chromosomes\n",
    "chromosomes = read_centromeres(centromere_file, scaffolds)\n",
    "\n",
    "# look at gene content in high and low regions\n",
    "abs_positions = {row['name']: row.abs_pos for i, row in scaffolds.iterrows()}\n",
    "annotation = gff_table(annotation_file)\n",
    "annotation = annotation.loc[annotation.feature == 'CDS'] # I only care about the CDS, not the start codons & exons etc\n",
    "scaf_adjustment = annotation.seqname.replace(abs_positions)\n",
    "annotation['abs_start'] = annotation.start + scaf_adjustment\n",
    "annotation['abs_end'] = annotation.end + scaf_adjustment\n",
    "\n",
    "def top_regions(data, annotation, top_size, outfile, ascending=False):\n",
    "    data = data.sort_values('E', ascending=ascending)\n",
    "    i = 0\n",
    "    total_length = 0\n",
    "    while total_length < top_size:\n",
    "        i += 1\n",
    "        top_windows = data.head(i)\n",
    "        top_regions, total_length = collapse_regions(top_windows)\n",
    "\n",
    "    fh = open(outfile, 'w')\n",
    "    geneIDs = set()\n",
    "    for start, end, length in top_regions:\n",
    "        features = annotation.loc[(annotation.abs_start <= end) & (annotation.abs_end >= start)]\n",
    "        genes = set(features.attributes)\n",
    "        geneIDs |= set([gene.split()[1][1:-2] for gene in genes])\n",
    "        fh.write( 'Region {}-{} ({} bp): {} genes\\n'.format(start, end, length, len(genes)) )\n",
    "        for gene in genes:\n",
    "            fh.write( '{}\\n'.format(gene) )\n",
    "        fh.write('\\n')\n",
    "    fh.close()\n",
    "\n",
    "    return geneIDs, total_length\n",
    "\n",
    "def collapse_regions(data):\n",
    "    data = data.sort_values('start')\n",
    "    regions = []\n",
    "    total_length = 0\n",
    "    region_start = 0\n",
    "    region_end = 0\n",
    "    for index, row in data.iterrows():\n",
    "        if row.start > region_end:\n",
    "            region_length = region_end - region_start\n",
    "            total_length += region_length\n",
    "            regions.append( (region_start, region_end, region_length) )\n",
    "            region_start = row.start\n",
    "        region_end = row.end\n",
    "    regions = regions[1:]\n",
    "    return regions, total_length\n",
    "\n",
    "most_size  = 2000000\n",
    "# Conserved regions\n",
    "low_genes, conserved_length = top_regions(certain, annotation, most_size, 'conserved_regions.txt', ascending=True)\n",
    "print('{} genes found in {} bp of conserved regions'.format(len(low_genes), conserved_length))\n",
    "high_genes, fragile_length = top_regions(certain, annotation, most_size, 'fragile_regions.txt', ascending=False)\n",
    "print('{} genes found in {} bp of fragile regions'.format(len(high_genes), fragile_length))\n",
    "\n",
    "def parse_core_genes(gene_table, key_file):\n",
    "    gene_table = pd.read_csv(gene_table, delimiter='\\t', header=0)\n",
    "    keyfh = open(key_file, 'r')\n",
    "    ranks = {}\n",
    "    better_labels = {}\n",
    "    for line in keyfh:\n",
    "        rank, code, description = line.strip().split('\\t')\n",
    "        ranks[code] = int(rank)\n",
    "        better_labels[code] = description\n",
    "    gene_table['coreness'] = gene_table.ID30\n",
    "    gene_table.coreness.replace(ranks, inplace=True)\n",
    "    gene_table.ID30.replace(better_labels, inplace=True)\n",
    "    gene_table.sort_values('coreness', inplace=True)\n",
    "\n",
    "    return gene_table\n",
    "\n",
    "def core_enrichment(genes, core_genes):\n",
    "    core_genes_present = core_genes.loc[core_genes.Broad7_geneID.isin(genes)]\n",
    "\n",
    "    category_counts = {}\n",
    "    label_order = []\n",
    "    for i, row in core_genes_present.iterrows():\n",
    "        try:\n",
    "            category_counts[row.ID30] += 1\n",
    "        except KeyError:\n",
    "            category_counts[row.ID30] = 1\n",
    "            label_order.append(row.ID30)\n",
    "    label_order = [l for l in label_order if l != 'Others']\n",
    "\n",
    "    return category_counts, label_order\n",
    "\n",
    "# Compare core gene content of high and low genes\n",
    "print()\n",
    "core_genes = parse_core_genes(core_gene_file, core_gene_key)\n",
    "lowcounts, label_order = core_enrichment(low_genes, core_genes)\n",
    "highcounts, label_order = core_enrichment(high_genes, core_genes)\n",
    "label_order = label_order[::-1]\n",
    "diffcounts = [lowcounts[label]-highcounts[label] for label in label_order]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (6, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "bars = pretty_bar(ax, diffcounts, label_order, horizontal=True)\n",
    "direct_labels(ax, list(range(len(diffcounts))), diffcounts, horizontal=True, num_format='0:+')\n",
    "direct_labels(ax, list(range(len(diffcounts))),\n",
    "              [((n<0)*2)-1 for n in diffcounts],\n",
    "              altlabels=[highcounts[l] for l in label_order],\n",
    "              horizontal=True)\n",
    "ax.set_xlim(-105, 105)\n",
    "ax.set_xlabel('Conserved Genes - Fragile Genes')\n",
    "fig.savefig('core_gene_content')\n",
    "\n",
    "core_genes_in_category = {}\n",
    "for i, row in core_genes.iterrows():\n",
    "    try:\n",
    "        core_genes_in_category[row.ID30] += 1\n",
    "    except KeyError:\n",
    "        core_genes_in_category[row.ID30] = 1\n",
    "print('{} genes have a published phylogenetic distribution'.format(sum(core_genes_in_category.values())))\n",
    "for category, number in list(core_genes_in_category.items()):\n",
    "    print('{}\\t{}'.format(number, category))\n",
    "\n",
    "print('{} / {} genes in conserved regions have published phylogenetic distribution'.format(sum(lowcounts.values()), len(low_genes)))\n",
    "print('{} / {} genes in fragile regions have published phylogenetic distribution'.format(sum(highcounts.values()), len(high_genes)))\n",
    "print()\n",
    "\n",
    "distributions = [[lowcounts[label] for label in label_order],\n",
    "                 [highcounts[label] for label in label_order]]\n",
    "chi2, pval, dof, expected = stats.chi2_contingency(distributions)\n",
    "print('2-sample Chi-squared test if the distribution of phylogenetic conservation of')\n",
    "print('genes in fragile (most rapidly breaking) and conserved regions are equal:')\n",
    "print('chi2', chi2)\n",
    "print('pval', pval)\n",
    "print('dof', dof)\n",
    "print()\n",
    "\n",
    "\n",
    "# is break rate correlated with distance to telomere?\n",
    "\n",
    "tests = telomere_correlations(certain, chromosomes, 'E')\n",
    "#tests.extend( telomere_correlations(uncertain, chromosomes, 'E') )\n",
    "\n",
    "# multiple testing correction for testing each chromosome arm independently\n",
    "# use 'fdr_tsbh' for two stage fdr correction via Benjamini/Hochberg method\n",
    "p_vals = [test.raw_slope_p for test in tests]\n",
    "rejects, p_vals, bs, nonsense = smm.multipletests(p_vals, alpha=0.05, method='fdr_tsbh')\n",
    "\n",
    "\n",
    "sig_tests = []\n",
    "insig_tests = []\n",
    "print('label\\traw_p\\tp\\tslope\\tintercept\\tr_squared')\n",
    "for test, pv, reject in zip(tests, p_vals, rejects):\n",
    "    test.p_val = pv\n",
    "    print('{}\\t{:.2E}\\t{:.2E}\\t{:.2E}\\t{:.2E}\\t{:0.4f}'.format(test.label, test.raw_slope_p, pv, test.slope, test.intercept, test.r2))\n",
    "    if reject:\n",
    "        sig_tests.append(test)\n",
    "    else:\n",
    "        insig_tests.append(test)\n",
    "\n",
    "print('sig tests', len(sig_tests))\n",
    "print('insig tests', len(insig_tests))\n",
    "\n",
    "def grid_plots(tests, outfile, logy=True):\n",
    "    nplots = len(tests)\n",
    "    columns = 2\n",
    "    rows = int((nplots -1) / 2) + 1\n",
    "    plotsize = (4, 4)\n",
    "    figsize = (plotsize[0]*columns, plotsize[1]*rows)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    gs = gridspec.GridSpec(rows, columns)\n",
    "    axes = [fig.add_subplot(gs[x]) for x in range(nplots)]\n",
    "\n",
    "    for ax, test in zip(axes, tests):\n",
    "        test.draw(ax, logy = logy, fit_report_location = (0.05, 0.05))\n",
    "    fig.savefig(outfile, dpi=350)\n",
    "    plt.close(fig)\n",
    "\n",
    "grid_plots(tests, 'brag_correlations')\n",
    "\n",
    "# is CRI correlated with distance to telomere?\n",
    "\n",
    "print('regression of CRI w/ telomere distance')\n",
    "\n",
    "extra_tracks = pd.read_csv('Ncra_extra_tracks.tsv', sep='\\t', header=0)\n",
    "\n",
    "tests = telomere_correlations(extra_tracks, chromosomes, 'CRI')\n",
    "\n",
    "# multiple testing correction for testing each chromosome arm independently\n",
    "# use 'fdr_tsbh' for two stage fdr correction via Benjamini/Hochberg method\n",
    "p_vals = [test.raw_slope_p for test in tests]\n",
    "rejects, p_vals, bs, nonsense = smm.multipletests(p_vals, alpha=0.05, method='fdr_tsbh')\n",
    "\n",
    "\n",
    "sig_tests = []\n",
    "insig_tests = []\n",
    "print('label\\traw_p\\tp\\tslope\\tintercept\\tr_squared')\n",
    "for test, pv, reject in zip(tests, p_vals, rejects):\n",
    "    test.p_val = pv\n",
    "    print('{}\\t{:.2E}\\t{:.2E}\\t{:.2E}\\t{:.2E}\\t{:0.4f}'.format(test.label, test.raw_slope_p, pv, test.slope, test.intercept, test.r2))\n",
    "    if reject:\n",
    "        sig_tests.append(test)\n",
    "    else:\n",
    "        insig_tests.append(test)\n",
    "\n",
    "print('sig tests', len(sig_tests))\n",
    "print('insig tests', len(insig_tests))\n",
    "\n",
    "grid_plots(tests, 'CRI_correlations', logy=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
